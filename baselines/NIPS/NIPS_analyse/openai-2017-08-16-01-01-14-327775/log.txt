Arguments:
actor_lr: 0.0001
batch_size: 64
bind_to_core: False
clip_norm: None
critic_l2_reg: 0.01
critic_lr: 0.001
evaluation: True
gamma: 0.99
gym_monitor: False
layer_norm: False
logdir: /home/dmarta/baselines/baselines/NIPS/NIPS_analyse/openai-2017-08-16-01-01-14-327775
nb_epoch_cycles: 1
nb_epochs: 5
nb_eval_steps: 100
nb_rollout_steps: 100
nb_train_steps: 50
noise_type: adaptive-param_0.2
normalize_observations: True
normalize_returns: False
num_cpu: 2
popart: False
render: False
render_eval: False
reward_scale: 1.0
seed: 0
test: False

Directory is /home/dmarta/baselines/baselines/NIPS/NIPS_analyse/openai-2017-08-16-01-01-14-327775
rank 0: seed=0, logdir=/home/dmarta/baselines/baselines/NIPS/NIPS_analyse/openai-2017-08-16-01-01-14-327775
scaling actions by [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.] before executing in env
setting up param noise
  param_noise_actor/dense/kernel:0 <- actor/dense/kernel:0 + noise
  param_noise_actor/dense/bias:0 <- actor/dense/bias:0 + noise
  param_noise_actor/dense_1/kernel:0 <- actor/dense_1/kernel:0 + noise
  param_noise_actor/dense_1/bias:0 <- actor/dense_1/bias:0 + noise
  param_noise_actor/dense_2/kernel:0 <- actor/dense_2/kernel:0 + noise
  param_noise_actor/dense_2/bias:0 <- actor/dense_2/bias:0 + noise
  adaptive_param_noise_actor/dense/kernel:0 <- actor/dense/kernel:0 + noise
  adaptive_param_noise_actor/dense/bias:0 <- actor/dense/bias:0 + noise
  adaptive_param_noise_actor/dense_1/kernel:0 <- actor/dense_1/kernel:0 + noise
  adaptive_param_noise_actor/dense_1/bias:0 <- actor/dense_1/bias:0 + noise
  adaptive_param_noise_actor/dense_2/kernel:0 <- actor/dense_2/kernel:0 + noise
  adaptive_param_noise_actor/dense_2/bias:0 <- actor/dense_2/bias:0 + noise
setting up actor optimizer
  actor shapes: [[41, 64], [64], [64, 64], [64], [64, 18], [18]]
  actor params: 8018
setting up critic optimizer
  regularizing: critic/dense/kernel:0
  regularizing: critic/dense_1/kernel:0
  regularizing: critic/dense_2/kernel:0
  applying l2 regularization with 0.01
  critic shapes: [[41, 64], [64], [82, 64], [64], [64, 1], [1]]
  critic params: 8065
setting up target updates ...
  target_actor/dense/kernel:0 <- actor/dense/kernel:0
  target_actor/dense/bias:0 <- actor/dense/bias:0
  target_actor/dense_1/kernel:0 <- actor/dense_1/kernel:0
  target_actor/dense_1/bias:0 <- actor/dense_1/bias:0
  target_actor/dense_2/kernel:0 <- actor/dense_2/kernel:0
  target_actor/dense_2/bias:0 <- actor/dense_2/bias:0
setting up target updates ...
  target_critic/dense/kernel:0 <- critic/dense/kernel:0
  target_critic/dense/bias:0 <- critic/dense/bias:0
  target_critic/dense_1/kernel:0 <- critic/dense_1/kernel:0
  target_critic/dense_1/bias:0 <- critic/dense_1/bias:0
  target_critic/dense_2/kernel:0 <- critic/dense_2/kernel:0
  target_critic/dense_2/bias:0 <- critic/dense_2/bias:0
Using agent with the following configuration:
dict_items([('obs0', <tf.Tensor 'obs0:0' shape=(?, 41) dtype=float32>), ('obs1', <tf.Tensor 'obs1:0' shape=(?, 41) dtype=float32>), ('terminals1', <tf.Tensor 'terminals1:0' shape=(?, 1) dtype=float32>), ('rewards', <tf.Tensor 'rewards:0' shape=(?, 1) dtype=float32>), ('actions', <tf.Tensor 'actions:0' shape=(?, 18) dtype=float32>), ('critic_target', <tf.Tensor 'critic_target:0' shape=(?, 1) dtype=float32>), ('param_noise_stddev', <tf.Tensor 'param_noise_stddev:0' shape=() dtype=float32>), ('gamma', 0.99), ('tau', 0.01), ('memory', <baselines.ddpg.memory.Memory object at 0x7fb8e8f5a898>), ('normalize_observations', True), ('normalize_returns', False), ('action_noise', None), ('param_noise', AdaptiveParamNoiseSpec(initial_stddev=0.2, desired_action_stddev=0.2, adoption_coefficient=1.01)), ('action_range', (-1.0, 1.0)), ('return_range', (-inf, inf)), ('observation_range', (-5.0, 5.0)), ('critic', <baselines.ddpg.models.Critic object at 0x7fb8e8f5aba8>), ('actor', <baselines.ddpg.models.Actor object at 0x7fb8e8f5aa20>), ('actor_lr', 0.0001), ('critic_lr', 0.001), ('clip_norm', None), ('enable_popart', False), ('reward_scale', 1.0), ('batch_size', 64), ('stats_sample', None), ('critic_l2_reg', 0.01), ('obs_rms', <baselines.common.mpi_running_mean_std.RunningMeanStd object at 0x7fb8e8f60048>), ('ret_rms', None), ('target_actor', <baselines.ddpg.models.Actor object at 0x7fb8e8f607b8>), ('target_critic', <baselines.ddpg.models.Critic object at 0x7fb8e8f60208>), ('actor_tf', <tf.Tensor 'actor/Tanh:0' shape=(?, 18) dtype=float32>), ('normalized_critic_tf', <tf.Tensor 'critic/dense_3/BiasAdd:0' shape=(?, 1) dtype=float32>), ('critic_tf', <tf.Tensor 'clip_by_value_2:0' shape=(?, 1) dtype=float32>), ('normalized_critic_with_actor_tf', <tf.Tensor 'critic_1/dense_3/BiasAdd:0' shape=(?, 1) dtype=float32>), ('critic_with_actor_tf', <tf.Tensor 'clip_by_value_3:0' shape=(?, 1) dtype=float32>), ('target_Q', <tf.Tensor 'add:0' shape=(?, 1) dtype=float32>), ('perturbed_actor_tf', <tf.Tensor 'param_noise_actor/Tanh:0' shape=(?, 18) dtype=float32>), ('perturb_policy_ops', <tf.Operation 'group_deps' type=NoOp>), ('perturb_adaptive_policy_ops', <tf.Operation 'group_deps_1' type=NoOp>), ('adaptive_policy_distance', <tf.Tensor 'Sqrt:0' shape=() dtype=float32>), ('actor_loss', <tf.Tensor 'Neg:0' shape=() dtype=float32>), ('actor_grads', <tf.Tensor 'concat:0' shape=(8018,) dtype=float32>), ('actor_optimizer', <baselines.common.mpi_adam.MpiAdam object at 0x7fb8e8d52b00>), ('critic_loss', <tf.Tensor 'add_13:0' shape=() dtype=float32>), ('critic_grads', <tf.Tensor 'concat_2:0' shape=(8065,) dtype=float32>), ('critic_optimizer', <baselines.common.mpi_adam.MpiAdam object at 0x7fb8e8c13908>), ('stats_ops', [<tf.Tensor 'Mean_3:0' shape=() dtype=float32>, <tf.Tensor 'Mean_4:0' shape=() dtype=float32>, <tf.Tensor 'Mean_5:0' shape=() dtype=float32>, <tf.Tensor 'Sqrt_1:0' shape=() dtype=float32>, <tf.Tensor 'Mean_8:0' shape=() dtype=float32>, <tf.Tensor 'Sqrt_2:0' shape=() dtype=float32>, <tf.Tensor 'Mean_11:0' shape=() dtype=float32>, <tf.Tensor 'Sqrt_3:0' shape=() dtype=float32>, <tf.Tensor 'Mean_14:0' shape=() dtype=float32>, <tf.Tensor 'Sqrt_4:0' shape=() dtype=float32>]), ('stats_names', ['obs_rms_mean', 'obs_rms_std', 'reference_Q_mean', 'reference_Q_std', 'reference_actor_Q_mean', 'reference_actor_Q_std', 'reference_action_mean', 'reference_action_std', 'reference_perturbed_action_mean', 'reference_perturbed_action_std']), ('target_init_updates', [<tf.Operation 'group_deps_4' type=NoOp>, <tf.Operation 'group_deps_6' type=NoOp>]), ('target_soft_updates', [<tf.Operation 'group_deps_5' type=NoOp>, <tf.Operation 'group_deps_7' type=NoOp>])])
Starting a new epoch_cycle nº 0 =)
--------------------------------------
| obs_rms_mean            | 0.212    |
| obs_rms_std             | 0.696    |
| param_noise_stddev      | 0.122    |
| reference_Q_mean        | -0.182   |
| reference_Q_std         | 0.115    |
| reference_action_mean   | -0.0221  |
| reference_action_std    | 0.0845   |
| reference_actor_Q_mean  | -0.108   |
| reference_actor_Q_std   | 0.0876   |
| reference_perturbed_... | 0.756    |
| rollout/Q_mean          | 0.00173  |
| rollout/actions_mean    | 0.372    |
| rollout/actions_std     | 0.641    |
| rollout/episode_steps   | 0        |
| rollout/episodes        | 0        |
| rollout/return          | 0        |
| rollout/return_history  | nan      |
| total/duration          | 18.5     |
| total/episodes          | 0        |
| total/epochs            | 1        |
| total/steps             | 100      |
| total/steps_per_second  | 5.41     |
| train/loss_actor        | 0.0918   |
| train/loss_critic       | 0.443    |
| train/param_noise_di... | 0.623    |
--------------------------------------

Starting a new epoch_cycle nº 0 =)
Episode ended nº 1
--------------------------------------
| obs_rms_mean            | 0.184    |
| obs_rms_std             | 0.674    |
| param_noise_stddev      | 0.0739   |
| reference_Q_mean        | -0.212   |
| reference_Q_std         | 0.156    |
| reference_action_mean   | -0.0678  |
| reference_action_std    | 0.278    |
| reference_actor_Q_mean  | -0.0295  |
| reference_actor_Q_std   | 0.11     |
| reference_perturbed_... | 0.46     |
| rollout/Q_mean          | -0.0561  |
| rollout/actions_mean    | 0.424    |
| rollout/actions_std     | 0.614    |
| rollout/episode_steps   | 132      |
| rollout/episodes        | 2        |
| rollout/return          | -32.3    |
| rollout/return_history  | -32.3    |
| total/duration          | 30.8     |
| total/episodes          | 1        |
| total/epochs            | 2        |
| total/steps             | 200      |
| total/steps_per_second  | 6.5      |
| train/loss_actor        | 0.103    |
| train/loss_critic       | 0.211    |
| train/param_noise_di... | 0.433    |
--------------------------------------

Starting a new epoch_cycle nº 0 =)
Episode ended nº 2
--------------------------------------
| obs_rms_mean            | 0.172    |
| obs_rms_std             | 0.657    |
| param_noise_stddev      | 0.0459   |
| reference_Q_mean        | -0.221   |
| reference_Q_std         | 0.197    |
| reference_action_mean   | -0.0883  |
| reference_action_std    | 0.508    |
| reference_actor_Q_mean  | 0.00312  |
| reference_actor_Q_std   | 0.149    |
| reference_perturbed_... | 0.471    |
| rollout/Q_mean          | -0.0404  |
| rollout/actions_mean    | 0.427    |
| rollout/actions_std     | 0.567    |
| rollout/episode_steps   | 128      |
| rollout/episodes        | 4        |
| rollout/return          | -14.6    |
| rollout/return_history  | -14.6    |
| total/duration          | 43.1     |
| total/episodes          | 2        |
| total/epochs            | 3        |
| total/steps             | 300      |
| total/steps_per_second  | 6.96     |
| train/loss_actor        | 0.047    |
| train/loss_critic       | 0.0998   |
| train/param_noise_di... | 0.281    |
--------------------------------------

Starting a new epoch_cycle nº 0 =)
Episode ended nº 3
--------------------------------------
| obs_rms_mean            | 0.144    |
| obs_rms_std             | 0.666    |
| param_noise_stddev      | 0.0441   |
| reference_Q_mean        | -0.201   |
| reference_Q_std         | 0.22     |
| reference_action_mean   | -0.0553  |
| reference_action_std    | 0.64     |
| reference_actor_Q_mean  | -0.00859 |
| reference_actor_Q_std   | 0.185    |
| reference_perturbed_... | 0.536    |
| rollout/Q_mean          | -0.0245  |
| rollout/actions_mean    | 0.491    |
| rollout/actions_std     | 0.514    |
| rollout/episode_steps   | 116      |
| rollout/episodes        | 6        |
| rollout/return          | -12      |
| rollout/return_history  | -12      |
| total/duration          | 72.5     |
| total/episodes          | 3        |
| total/epochs            | 4        |
| total/steps             | 400      |
| total/steps_per_second  | 5.52     |
| train/loss_actor        | 0.0429   |
| train/loss_critic       | 0.0477   |
| train/param_noise_di... | 0.206    |
--------------------------------------

Starting a new epoch_cycle nº 0 =)
Episode ended nº 4
---------------------------------------
| obs_rms_mean            | 0.14      |
| obs_rms_std             | 0.628     |
| param_noise_stddev      | 0.0441    |
| reference_Q_mean        | -0.185    |
| reference_Q_std         | 0.262     |
| reference_action_mean   | -0.000806 |
| reference_action_std    | 0.706     |
| reference_actor_Q_mean  | -0.0375   |
| reference_actor_Q_std   | 0.253     |
| reference_perturbed_... | 0.578     |
| rollout/Q_mean          | -0.0233   |
| rollout/actions_mean    | 0.493     |
| rollout/actions_std     | 0.476     |
| rollout/episode_steps   | 113       |
| rollout/episodes        | 7         |
| rollout/return          | -9.16     |
| rollout/return_history  | -9.09     |
| total/duration          | 102       |
| total/episodes          | 3.5       |
| total/epochs            | 5         |
| total/steps             | 500       |
| total/steps_per_second  | 4.92      |
| train/loss_actor        | 0.0278    |
| train/loss_critic       | 0.0271    |
| train/param_noise_di... | 0.199     |
---------------------------------------

Model saved in file: /home/dmarta/baselines/baselines/NIPS/NIPS_analyse/model
total runtime: 102.40461945533752s
